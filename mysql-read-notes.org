** 高性能 mysql (第 3 版)


*** 读写锁(第 4 页)
#+BEGIN_EXAMPLE
处理并发读或者写时, 可以通过锁来解决问题.
锁又分为 共享锁(shared lock) 和 排他锁(exclusive lock), 也叫 读锁(read lock) 和 写锁(write lock).

可以这么理解: 读(read)锁是共享(shared)的, 相互之间不会阻塞. 而写(write)锁是排他(exclusive)的.
#+END_EXAMPLE


*** 锁粒度
#+BEGIN_EXAMPLE
所谓锁策略就是在锁的开销和数据安全性之间寻求平衡, 这种平衡会影响到性能.

mysql 锁策略有: 表锁(table lock) 和 行级锁(row lock)

表锁是最基本的策略, 开销最小, 它会锁定整张表.
行级锁可以最大程度支持并发. 行级锁只在存留引擎层实现, 服务器层没有实现.
#+END_EXAMPLE


*** 隔离级别
| 隔离级别                   | 导致脏读? | 导致不可重复读? | 导致幻读? | 加锁读 |
| 读未提交(read uncommitted) | Yes       | Yes             | Yes       | No     |
| 读提交(read committed)     | No        | Yes             | Yes       | No     |
| 重复读(repeatable read)    | No        | No              | Yes       | No     |
| 串行化(serializable)       | No        | No              | No        | Yes    |

*个人观点*
: 重复读(repeatable read)这个级别 是数据库理论过度学术导致的问题.
:   这是强行为了 事务的隔离性 而学术过度的级别:
:     单个事务中同样的条件在不同时间点读到了不同的数据, 在现实生活中这本身就是合理的, 可想而知是数据在其他地方被改变了.


*** 死锁(第 9 页)
*死锁是指两个或以上的事务在同一资源上相互占用并请求锁定对方占用的资源从而导致恶性循环的现象.*
当多个事务试图以不同的顺序锁定资源时, 就可能会产生死锁. 多个事务同时锁定同一资源也会产生死锁.

事务一
#+BEGIN_SRC sql
begin;
update t1 set c1 = x where c2 = 1;   -- 1
update t1 set c1 = y where c2 = 2;   -- 3
commit;                              -- 5
#+END_SRC

事务二
#+BEGIN_SRC sql
begin;
update t1 set c1 = yy where c2 = 2;  -- 2
update t1 set c1 = xx where c2 = 1;  -- 4
commit;                              -- 6
#+END_SRC

#+BEGIN_EXAMPLE
上面的两个事务如果按执行时间运行(其中 5 和 6 可以互换), 将会产生死锁.

如果 t1 表是 InnoDB 存储引擎(其处理死锁的方法是 将持有最少行级排他锁的事务进行回滚):
第 3 步运行会导致 事务一 阻塞
第 4 步运行会错误: 1213, deadlock found when trying to get lock;try restarting transation
     此时 3 的阻塞会释放并提示修改了一条记录
事务二的提交动作将不会对任何数据有影响
事务一的提交动作将会影响两条数据

也就是说: 生效的数据 来自于 出现竞争时先操作的那个事务
#+END_EXAMPLE


*** 多版本并发控制(mvcc)

mvcc 是行级锁的一个变种, 它避免了加锁操作, 因此开销更低.

它是通过保存数据在某个时间点的快照来实现的. 其只在 rr 和 rc 两个隔离级别下工作, 其他两个不兼容. ru 总是读最新行, s 会对读到的行加锁.


*** innodb 存储引擎
#+BEGIN_EXAMPLE
其采用 mvcc 来支持高并发, 其默认隔离级别是 rr, 并通过 间隙锁(next-key locking)策略 防止幻读.
间隙锁使得 innodb 不仅锁定查询涉及的行, 还会对索引中的间隙进行锁定, 以防止幻影行的插入.
#+END_EXAMPLE


*** 范式的优点和缺点(第 130 页)
范式化带来的好处有:
+ 范式化的更新操作通常比反范式化要快
+ 当数据较好地范式化时, 就只有很少或没有重复数据, 所以只需要修改更少的数据
+ 范式化的表通常更小, 可以更好地放在内存时, 执行操作会更快

范式化设计的 scheme 缺点是通常都需要关联.
: PS: mysql 限制了每个关联操作最多只能有 61 张表, 单查询最好保持在 12 个表以内做关联


*** 多列索引(第 157 页)
5.0 及以上引入了一种叫 *索引合并(index merge) 的策略, 可以使用表上的多个单列索引来定位指定的行*.

#+BEGIN_SRC sql
select xxx from t1 where c1 = 1 or c2 = 2;
#+END_SRC

在 5.0 以前, mysql 会对这个查询使用全表扫描. 除非改成下面的方式查询
#+BEGIN_SRC sql
select xxx from t1 where c1 = 1
union all
select xxx from t1 where t2 = 2 and t1 != 1;
#+END_SRC

但在 5.0 及以上版本中, 查询能够同时使用这两个单列索引进行扫描, 并将结果进行合并.

索引合并策略有时候是一种优化的结果, 但实际上更多时候说明了表上的索引建得很糟糕:
+ 当对多个索引做相交操作(多个 and 条件)时, 通常意味着需要一个包含所有相关列的多列索引, 而不是多个独立的单列索引.
+ 当对多个索引做联合操作(多个 or 条件)时, 通常需要耗费大量 cpu 和 内存资源 在算法的缓存、排序和合并操作上.


*** 支持多种过滤条件(第 183 页)
#+BEGIN_EXAMPLE
考虑表上所有的选项: 当设计索引时, 不要只为现有的查询考虑需要哪些索引, 还需要考虑对查询进行优化.
比如有 sex 这个字段做为联合索引, 当有些查询不需要此字段时, 也可以用 sex in('f', 'm') 来达到使用索引的效果.

查询只能使用索引的最左前缀, 直到遇到第一个范围条件列.
因此: 尽可能将需要做范围查询的列放在索引的后面, 以便优化器使用尽可能多的索引列.
#+END_EXAMPLE


*** 是否在扫描额外的记录(第 198 页)
mysql 能使用如下三种方式应用 where 条件, 从好到坏依次为:
+ 在索引中使用 where 条件来过滤不匹配的记录, 这是在存储引擎层完成的
+ 使用索引覆盖扫描(extra 列出现了 using index)来返回记录, 
    直接从索引中过滤不需要的记录并返回命中的结果. 由 mysql 服务器层完成, 无须回表查询记录.
+ 从数据表返回数据, 然后过滤不满足的记录(extra 列中出现了 using where).
    由 mysql 服务器层完成, 需要先从数据表读出记录然后过滤.

如果发现查询扫描了大量的数据但只返回了少数的行, 可以尝试下面的技巧来优化:
+ 使用索引覆盖扫描, 把需要用的列都放到索引中, 这样存储引擎无须回表就可以返回结果
+ 改变库表结构, 例如使用单独的汇总表.
+ 重写复杂查询, 让优化器能够以更优化的执行查询


*** 重构查询的方法(第 201 页)
很多高性能的应用都会对关联查询进行分解, 对每一个表进行一次单表查询, 然后将结果在应用中进行关联. 

用分解关联查询的方重构有如下优势:
+ 让缓存的效率更高
+ 查询分解后, 单个查询可以减少锁竞争
+ 在应用层做关联, 可以更容易对数据库做拆分, 更容易做到高性能和可扩展
+ 查询本身效率也可能会有所提升. 使用 in 代替关联查询可以让 mysql 按照 id 顺序进行查询, 这比随机关联要更高效
+ 减少冗余记录的查询, 在应用层做关联, 某条记录应用只需要查询一次, 
    而在数据库做关联查询可能需要重复访问一部分数据. 这样的重构还能减少网络和内存的消耗

在很多场景下, 通过重构查询将关联放到应用程序中将会更高效, 比如:
+ 当应用能够方便地缓存单个查询结果时
+ 当可以将数据分页到不同的 mysql 服务器上时
+ 当使用 in 代替关联查询时
+ 当查询中使用同一个数据表时


*** 查询优化处理(第 208 页)
#+BEGIN_EXAMPLE
in 完全等同于多个 or 条件的子句. 这在 mysql 中并不成立. 其会将 in 列表中的数据先进行排序
再二分查找的方式来确定列表中的值是否满足条件, 这是一个 O(log n) 复杂度的操作, 等价转换成 or 后的查询复杂度为 O(n)
对于 in 列表中有大量聚会的时候, mysql 的处理速度将会更快.

mysql 总是从一个表开始一直嵌套循环, 回溯完成所有表关联. 所以 mysql 的执行计划是一棵左测深度优先的树.
#+END_EXAMPLE


*** 并行执行(第 229 页)
mysql 无法利用多核特性来并行执行查询. 很多其他的关系型数据能够提供这个特性, 但是 mysql 做不到.


*** 优化 count 查询
通配符 * 并不会像我们猜想的那样扩展成所有的列, 它会忽略所有的列而直接统计所有的行数.
如果希望返回结果集的行数, 最好使用 COUNT(*), 这样写意义清晰, 性能也会更好.

MyISAM 的 count 函数只在没有任何 where 条件时才非常快.

通常来说, COUNT 都需要扫描大量的行才能获得精确的结果, 因此是很难优化的. 可以增加 汇总表 或者 用外部缓存.
然后这样会陷入一个熟悉的困境: "快速, 精确和实现简单", 三者永远只能满足其二, 必须舍掉其中一个.


*** 查询缓存(第 309 页)
#+BEGIN_EXAMPLE
当判断缓存是否命中时, mysql 不会解析或参数化查询语句, 而是直接使用 sql 语句和客户端发过来的其他原始信息.
任何字符的不同, 如空格注解 --- 任何的不同 --- 都会导致缓存的不命中(percona 是例外, 它会先删除注释再比较语句)

当缓存中有不确定的数据(比如包含函数等)将不会被缓存.

如果查询语句中包含任何的不确定函数, 那么在查询缓存中是不可能找到缓存结果的
#+END_EXAMPLE


*** 复制的原理(第 445 页)
主要有基于语句(statement)和基于行(row)的两种复制

在 5.0 及之前只支持基于语句的复制(也叫逻辑复制). 最明显的好处是实现简单(但是同一条语句在不同的库执行会产生不同的结果, 如 now() 等)
另外, 它的更新必须是串行的, 这需要更多的锁.

从 5.1 开始支持基于行的复制, 它会将实际数据记录在二进制中. 其好处是可以更有效地复制. 但是, 如果这样一条语句
#+BEGIN_SRC sql
update t1 set c1 = 10;
#+END_SRC
由于做了全表更新, 基于行的复制开销会很大, 因为每一行都被记录到日志中.

没有哪种模式是完美的, 理论上来说 基于行的复制 模式整体上更优


*** 向外扩展(第 510 页)
向外扩展(也叫横向扩展和水平扩展)策略分为三个部分: 复制、拆分、和数据分片(sharding)

最简单也最常见的扩展方式是通过复制将数据分发到多个服务器, 然后将备库用于读查询.
#+BEGIN_EXAMPLE
分片? 还是不分片?

对单台服务器来说, 数据量太大时, 分片是不可避免的. 如果不分片, 而是尽可能地优化应用也能到达一个量级.
分片不是城里唯一的游戏, 在没有必要的情况下借用分片架构来构建应用会步履维艰.
#+END_EXAMPLE


*** 直接连接(第 534 页)
#+BEGIN_EXAMPLE
读写分离

基于查询分离: 最简单的分离方法是将所有不能容忍脏数据的读和写查询分配到主服务器上, 其他的读查询分配到备库上.
该策略很容易实现, 但事实上无法有效地使用备库, 因为只有很少的查询能容忍脏数据.

基于数据分离: 对查询分离的小改进. 需要让应用检查复制延迟, 以确定备库数据是否太旧.
比如许多报表类的应用: 只需要晚上加载数据复制到备库即可.

另外还有 基于会话分离 基于版本分离 基于全局版本/会话分离
#+END_EXAMPLE


*** 负载均衡算法(第 538 页)
决定 由哪个服务器接收下一个连接的算法 主要有: 随机、轮询、最少连接数、最快响应、哈希、权重
哪种算法最优取决于具体的工作负载. 比如最少连接, 如果有新机器加入可能会导致大量连接涌入该服务器.



-----



** mysql 技术内幕 - InnoDB 存储引擎(第 2 版)

*** 缓存池(第 22 页)
InnoDB 中的缓冲池是通过 LRU(latest recent used, 最近最少使用)算法来进行管理的.
也就是最频繁使用的页在 LRU 列表的前端, 而最少使用的页在 LRU 列表的尾端. 尾端数据空间将在不够时先被释放


*** 锁(第 249 页)
InnoDB 存储引擎实现了两种标准的行级锁:
+ 共享锁(S Lock), 允许事务读一行数据
+ 排他锁(X Lock), 允许事务删除或更新一行数据

InnoDB 存储引擎支持意向锁, 其意向锁即为表级别的锁. 主要是为了在一个事务中揭示下一行将被请求的锁类型. 其支持:
+ 意向共享锁(IS Lock), 事务想要获得一张表中某几行的共享锁
+ 意向排他锁(IX Lock), 事务想要获得一张表中某几行的其他锁
由于 InnoDB 支持的是行级锁, 因此意向锁不会阻塞除全表扫描外的任何请求

一致性非锁定读(consistent nonlocking read)是指通过行的多版本控制(multi versioning)的方式来读取当前执行时间中的数据.
如果读取的行正在执行 delete 或 update 操作, 这时读取操作不会去等待行上面锁的释放, 而是去读一个快照数据.

在 read-committed 级别下, 它总是读取被锁定行的最新一份快照数据.
而在 repeatable-read 级别下, 它总是读取事务开始时的行数据版本. 如下

事务一
#+BEGIN_SRC sql
begin;
select * from t1 where c1 = 1;  -- 1
-- do some thing
select * from t1 where c1 = 1;  -- 3
commit;
#+END_SRC

事务二
#+BEGIN_SRC sql
begin;
update t1 set c2 = 100 where c1 = 1;  -- 2
commit;
#+END_SRC

如果在 read-committed 级别下, 第 3 步的数据将会拿到更新后的 c2 的值.
而如果是在 repeatable-read 级别下, 第 1 步和 第 3 步获取的数据结果是一样的.
(如果只有事务一且 1 和 3 之间进行了 update t1 set xx where c1 = 1 操作, 第 3 步获取的数据将会是被更新过的)

InnoDB 的行锁有 3 种算法
+ Record Lock   : 单个行记录上的锁
+ Gap Lock      : 间隙锁, 锁定一个范围, 但不包含记录本身
+ Next-Key Lock : 上面二者的合并, 锁定一个范围, 并锁定记录本身

Next-Key Lock 的设计上的是为了解决幻读(phantom problem).
所谓幻读是在同一事务下, 连续两次同样的 sql 返回了不同的结果.

脏读是指在不同的事务下, 当前事务读到了另外事务未提交的数据.
不可重复读是指一个事务内读到了已经提交的数据.

不可重复读的问题是可以接受的. 因为它读到的就是已经提交的数据, 这本身不会带来什么问题.
所以 oracle, sql server 将 rc 设置为默认级别, 如果 mysql 的 binlog 使用 row 复制也可以使用 rc 级别.

PS: 熟悉 xtraBackup 工具

-----

*mysql 使用 rr 做为默认隔离级别的主要原因是在于 binlog.*

在 5.1 之前, 基于语句(statement) 是 binlog 的默认格式, 之后就有了 row(行) 和 mixed(混用) 两种模式.
从 5.1 开始, 如果使用 基于语句(statement) 的 binlog(以 commit 为序), 将不支持 rc 和 ru 级别.
要想使用 rc 级别, 必须使用 row(行) 或 mixed(混用) 模式.

为什么 rc 级别不支持 基于语句(statement) 的 binlog 呢? 假设有下面的表
#+BEGIN_SRC sql
drop table t1;
drop table t2;
create table t1(c1 int, c2 int);
create table t2(c1 int, c2 int);

insert into t1 values(1,1), (2,2);
insert into t2 values(1,1), (2,2);
#+END_SRC

会话一
#+BEGIN_SRC sql
select @@tx_isolation;  -- 8 及之后的版本改成了 transaction_isolation
set tx_isolation='read-committed';
begin;
update t2 set c2 = 3 where c1 in (select c1 from t1);  -- 1  括号里的 c1 有 1,2
update t2 set c2 = 4 where c1 in (select c1 from t1);  -- 4  括号里的 c1 只有 1
select * from t2;  -- 此时查询两行数据, 第一行是 1 4, 第二行是 2 3
commit;
#+END_SRC

会话二
#+BEGIN_SRC sql
select @@tx_isolation;
set tx_isolation='read-committed';
begin;
delete from t1 where c1 = 2;  -- 2
commit;                       -- 3
#+END_SRC

由于 binlog 要求 sql 串行化, 而 binlog 是以提交时间来排序的. 因此在 binlog 中的顺序将是这样
#+BEGIN_SRC sql
set tx_isolation='read-committed';
begin;
delete from t1 where c1 = 2;
commit;

set tx_isolation='read-committed';
begin;
update t1 set c2 = 3 where c1 in (select c1 from t2);
update t1 set c2 = 4 where c1 in (select c1 from t2);
select * from t2;  -- 此时查询两行数据, 第一行是 1 4, 第二行是 2 2
commit;
#+END_SRC
所以在 5.1 及以上的 rc 级别下, 基于语句(statement)的 binlog 将会与预期的不一样, 如果是 基于行(row)的 binlog 就不会有这个问题

改成 rr 级别的会话一
#+BEGIN_SRC sql
select @@tx_isolation;
set tx_isolation='repeatable-read';
begin;
update t2 set c2 = 3 where c1 in (select c1 from t1);  -- 1
update t2 set c2 = 4 where c1 in (select c1 from t1);  -- 4
select * from t2;  -- 此时查询两行数据, 第一行是 1 4, 第二行是 2 3
commit;
#+END_SRC

改成 rr 级别的会话二
#+BEGIN_SRC sql
select @@tx_isolation;
set tx_isolation='repeatable-read';
begin;
delete from t1 where c1 = 2;  -- 2 ==> 阻塞...
commit;                       -- 3 ==> 无法在会话一的前面完成 commit
#+END_SRC
如果使用 rr 级别, 与 rc 级别不同的是, 在 rr 中由于要保证可重复读, 会话二的 delete 将会被会话一阻塞(第 2 步), 直到会话一提交或超时, 所以会话二的 commit 将会无法在会话一的前面 commit, 这样就保证了 基于语句(statement)的 binlog 不会出问题

5.0 的 rc 与 5.1 的 rr 使用类似的并发和上锁机制, 也就是说, 同样的 rc 级别在 5.0 和 5.1 上会有兼容问题
